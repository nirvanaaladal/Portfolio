{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"collapsed_sections":[],"mount_file_id":"1yYJps0PsVnUXszLsiORf_Pd88VS5Jh4Q","authorship_tag":"ABX9TyNmdy9M/QykhR0h+rSKqRq9"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","gpuClass":"standard"},"cells":[{"cell_type":"markdown","source":["# QUESTIONS ARE ANSWERED IN THE DOCUMENT"],"metadata":{"id":"EF60xtXq047T"}},{"cell_type":"code","execution_count":28,"metadata":{"id":"9O14fBKKS0NS","executionInfo":{"status":"ok","timestamp":1668426694632,"user_tz":-180,"elapsed":544,"user":{"displayName":"Nirvana Aladal","userId":"04260912069444827004"}}},"outputs":[],"source":["#importing libraries \n","\n","import urllib\n","\n","from PIL import Image\n","from torchvision import transforms\n","\n","from torchvision import transforms\n","import numpy as np\n","from PIL import Image\n","import matplotlib.pyplot as plt\n","import os\n","import random\n","import cv2\n"]},{"cell_type":"code","source":["import torch\n","\n","model1 = torch.hub.load('pytorch/vision:v0.10.0', 'alexnet', pretrained=True) #loading alexnet\n","model1.eval()\n","\n","model2 = torch.hub.load('pytorch/vision:v0.10.1', 'vgg16', pretrained=True) #loading vgg16\n","model2.eval()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":0},"id":"O-a3DNJKTo3V","executionInfo":{"status":"ok","timestamp":1668422252012,"user_tz":-180,"elapsed":1128,"user":{"displayName":"Nirvana Aladal","userId":"04260912069444827004"}},"outputId":"41827a7b-1a06-4b3b-87b5-67d3f598bf89"},"execution_count":9,"outputs":[{"output_type":"stream","name":"stderr","text":["Using cache found in /root/.cache/torch/hub/pytorch_vision_v0.10.0\n","Using cache found in /root/.cache/torch/hub/pytorch_vision_v0.10.1\n"]},{"output_type":"execute_result","data":{"text/plain":["VGG(\n","  (features): Sequential(\n","    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (1): ReLU(inplace=True)\n","    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (3): ReLU(inplace=True)\n","    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (6): ReLU(inplace=True)\n","    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (8): ReLU(inplace=True)\n","    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (11): ReLU(inplace=True)\n","    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (13): ReLU(inplace=True)\n","    (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (15): ReLU(inplace=True)\n","    (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","    (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (18): ReLU(inplace=True)\n","    (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (20): ReLU(inplace=True)\n","    (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (22): ReLU(inplace=True)\n","    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","    (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (25): ReLU(inplace=True)\n","    (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (27): ReLU(inplace=True)\n","    (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (29): ReLU(inplace=True)\n","    (30): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","  )\n","  (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))\n","  (classifier): Sequential(\n","    (0): Linear(in_features=25088, out_features=4096, bias=True)\n","    (1): ReLU(inplace=True)\n","    (2): Dropout(p=0.5, inplace=False)\n","    (3): Linear(in_features=4096, out_features=4096, bias=True)\n","    (4): ReLU(inplace=True)\n","    (5): Dropout(p=0.5, inplace=False)\n","    (6): Linear(in_features=4096, out_features=1000, bias=True)\n","  )\n",")"]},"metadata":{},"execution_count":9}]},{"cell_type":"code","source":["# Download an example image from the pytorch website\n","import urllib\n","url, filename = (\"https://github.com/pytorch/hub/raw/master/images/dog.jpg\", \"dog.jpg\")\n","try: urllib.URLopener().retrieve(url, filename)\n","except: urllib.request.urlretrieve(url, filename)\n","\n"],"metadata":{"id":"looTJ02imCYc","executionInfo":{"status":"ok","timestamp":1668422255871,"user_tz":-180,"elapsed":968,"user":{"displayName":"Nirvana Aladal","userId":"04260912069444827004"}}},"execution_count":10,"outputs":[]},{"cell_type":"code","source":["dir_list = os.listdir('/content/drive/MyDrive/Colab Notebooks/fruits_images') # https://www.geeksforgeeks.org/python-os-listdir-method/\n","\n","alex, vgg = [], []\n","\n","for filename in dir_list:\n","    input_image = Image.open(filename)\n","\n","    process = transforms.Compose([\n","    transforms.Resize(256),\n","    transforms.CenterCrop(224),\n","    transforms.ToTensor(),\n","    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n","    ])\n","    input_tensor = process(input_image)\n","    input_batch = input_tensor.unsqueeze(0) # create a mini-batch as expected by the model\n","\n","    input_batch = process(os.path.join(\"fruits_images\",filename))\n","    # move the input and model to GPU for speed if available\n","    if torch.cuda.is_available():\n","        input_batch = input_batch.to('cuda')\n","        model1.to('cuda')\n","    with torch.no_grad():\n","        alex_output = model1(input_batch)\n","        vgg_output = model2(input_batch)\n","    # Tensor of shape 1000, with confidence scores over Imagenet's 1000 classes\n","    # The output has unnormalized scores. To get probabilities, you can run a softmax on it.\n","    alex.append(torch.nn.functional.softmax(alex_output[0], dim=0))\n","    vgg.append(torch.nn.functional.softmax(vgg_output[0], dim=0))\n","    p_alex = torch.max(alex_output.data,1)\n","    p_vgg = torch.max(vgg_output.data,1)\n","\n","for j in range(len(dir_list)):\n","    # Read the categories\n","    with open(\"imagenet_classes.txt\", \"r\") as f:\n","        categories = [s.strip() for s in f.readlines()]\n","    # Show top categories per image\n","    top5_prob_alex, top5_catid_alex = torch.topk(p_alex[j], 1)\n","    top5_prob_vgg, top5_catid_vgg = torch.topk(p_vgg[j], 1)\n","    filename = Image.open(os.path.join(\"Classifiction_Images\",dir_list[j]))\n","    plt.imshow(filename)\n","    plt.show()\n","    print(\"Alexnet Prediction: \",categories[top5_catid_alex[0]], top5_prob_alex[0].item())\n","    print(\"VGG Prediction: \",categories[top5_catid_vgg[0]], top5_prob_vgg[0].item())\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":351},"id":"j7lZDGPPmDxa","executionInfo":{"status":"error","timestamp":1668426377435,"user_tz":-180,"elapsed":518,"user":{"displayName":"Nirvana Aladal","userId":"04260912069444827004"}},"outputId":"49e79bc0-588f-4a61-81e8-bcde5cb4f149"},"execution_count":27,"outputs":[{"output_type":"error","ename":"FileNotFoundError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-27-15b5d658a08f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfilename\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdir_list\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0minput_image\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     process = transforms.Compose([\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/PIL/Image.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(fp, mode)\u001b[0m\n\u001b[1;32m   2841\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2842\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2843\u001b[0;31m         \u001b[0mfp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuiltins\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2844\u001b[0m         \u001b[0mexclusive_fp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2845\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'strawberry_fruit_red_224063.jpg'"]}]},{"cell_type":"code","source":["#function to add noise\n","\n","img = cv2.imread(os.path.join(\"fruits_images\",dir_list[1]))\n","\n","pixelsNum = random.randint(300, 50000)\n","\n","for i in range(pixelsNum):  \n","    temp_x = np.random.randint(0, img.shape[0])\n","\n","    temp_y = np.random.randint(0, img.shape[1])\n","\n","    img[temp_x][temp_y] = 0\n","\n","for i in range(pixelsNum):  \n","\n","    temp_x = np.random.randint(0, img.shape[0])\n","\n","    temp_y = np.random.randint(0, img.shape[1])\n","\n","    img[temp_x][temp_y] = 255\n","\n","\n","cv2.imwrite(\"Adversarial_image.jpg\",img)\n","\n","  \n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":232},"id":"sr8WGSNU-Zd9","executionInfo":{"status":"error","timestamp":1668427403026,"user_tz":-180,"elapsed":559,"user":{"displayName":"Nirvana Aladal","userId":"04260912069444827004"}},"outputId":"8bb002e0-9a85-45ce-8fb2-027511ad25c8"},"execution_count":29,"outputs":[{"output_type":"error","ename":"AttributeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;32m<ipython-input-29-1ad671bbcbd1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpixelsNum\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m         \u001b[0mtemp_x\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0mtemp_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'shape'"]}]}]}